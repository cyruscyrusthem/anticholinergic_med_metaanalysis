---
title: "Anticholinergic Meta analysis"
output: 
  html_document:
    keep_md: true
---

### Load packages
```{r setup, results = 'hide', message = FALSE}
library(meta)
library(metafor) #As a technical note, with exception of the DerSimonian–Laird and the Paule–Mandel methods the rma.uni function of R package metafor is called internally in the metagen function. Thus, it is a good idea to install R package metafor to make all estimation methods available.
library(tidyverse)
```

### Data import
Import data (.csv) 
```{r data import, results = 'hide', warning = FALSE, message = FALSE}
library(readr)
Anticholinergic_Medication_R_data <- read_csv("Z:/PROJECTS/2018_Anticholinergic_Med_SR/Analysis/Anticholinergic_Medication_R_data.csv")
```

Assign data to `dat`
```{r assign dat}
dat <- Anticholinergic_Medication_R_data %>%
  filter(include == 1) #%>% #this currently filters out the 2 Stevenson outcomes where participants were no longer on medication. This decision does need to be checked, though. 
  #filter(quality > 4) # this removes all studies with quality below the median (5)
```

### Meta-analysis
#### Step 1: Average across studies
This step is necessary to ensure independence of each effect size entered into the meta-analysis. In the current form, most studies report multiple outcomes (time-points, medication, cognitive tests), and these results are dependent on each other, as they come from they come from overlapping samples of participants. 

Data are averaged **within studies** so that each study represents a single effect size.
In all cases of studies which included outcomes for different medications, all medications were either low or high potency, so outcomes were able averaged together (within the study).

Averaged results are assigned to `dat_study`

```{r study average}
dat_study <- dat %>%
  group_by(study) %>% #group by study so further calculations are done within each study
  mutate(g = mean(g, na.rm = T),
          st_err = mean(st_err, na.rm = T)) %>% #obtain average g and st err within each study, removing NAs from calculation
  filter(row_number()==1) %>% #make each study only appear on one row
  select(study, author, year, Potency, g, st_err) #select relevant data for analysis
```

#### Step 2: Run random effects model of all data
**Model 1: meta package**

* Use the Sidik-Jonkman method to estimate tau
* Use the Knapp-Hartung method

```{r meta whole mod1, results = 'hide'}
meta_all_mod1 <- metagen(g,
                    st_err,
                    data = dat_study,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ", #use Sidik-Jonkman method
                    hakn = T, #using the Knapp-Hartung method
                    prediction = T, #True = print prediction interval for future studies based on present evidence
                    sm = "SMD") #calculate SMD
```


Code for forest plot:
```{r meta forest whole mod1, fig.width=8, fig.height=12}
meta::forest(meta_all_mod1,
             sortvar = TE, #sort by effect size
             xlim = c(-1.5, 1.5),
             leftcols = "studlab",
             rightcols = c("TE", "ci"),
             #rightlabs = c("SMD", "95% CI"),
             text.random = "Overall effect",
             text.overall.random = TRUE)#
             #pooled.totals = TRUE) #found this here: https://rdrr.io/cran/meta/man/forest.html
```

**Model 2: meta package**

* Use the DerSimonian-Laird method (default) to estimate tau
* Not using Knapp-Hartung method

```{r meta whole mod2, results = 'hide'}
meta_all_mod2 <- metagen(g,
                          st_err,
                          data = dat_study,
                          studlab = paste(author, year),
                          comb.fixed = F,
                          comb.random = T,
                          hakn = F, # not using the Knapp-Hartung method
                          prediction = T, #True = print prediction interval for future studies based on present evidence
                          sm = "SMD")
```

Code for forest plot (not displayed):
```{r meta forest whole mod2, fig.width=8, fig.height=12, fig.show = 'hide'}
meta::forest(meta_all_mod2,
             sortvar = TE,
             xlim = c(-1.5, 1.5),
             leftcols = "studlab") #found this here: https://rdrr.io/cran/meta/man/forest.html
```

**Model 3: meta package**

* Use the Restricted Maximum-Likelihood method to estimate tau
* Not using Knapp-Hartung method

```{r meta whole mod3, results = 'hide'}
meta_all_mod3 <- metagen(g,
                          st_err,
                          data = dat_study,
                          studlab = paste(author, year),
                          comb.fixed = F,
                          comb.random = T,
                          method.tau = "REML",
                          hakn = F, # not using the Knapp-Hartung method
                          prediction = T, #True = print prediction interval for future studies based on present evidence
                          sm = "SMD")
```

Code for forest plot (not displayed):
```{r meta forest whole mod3, fig.width=8, fig.height=12, fig.show = 'hide'}
meta::forest(meta_all_mod2,
             sortvar = TE,
             xlim = c(-1.5, 1.5),
             leftcols = "studlab") #found this here: https://rdrr.io/cran/meta/man/forest.html
```

Compare the models:

Model | SMD | LL | UL | t (mod1)/z (mod 2) | p-value
------ | ------ | ------ | ------ | ------ | ------
1 | `r meta_all_mod1[["TE.random"]]` |`r meta_all_mod1[["lower.random"]]` | `r meta_all_mod1[["upper.random"]]` | `r meta_all_mod1[["zval.random"]]` | `r meta_all_mod1[["pval.random"]]`
2 | `r meta_all_mod2[["TE.random"]]` | `r meta_all_mod2[["lower.random"]]` | `r meta_all_mod2[["upper.random"]]` | `r meta_all_mod2[["zval.random"]]` | `r meta_all_mod2[["pval.random"]]`
3 | `r meta_all_mod3[["TE.random"]]` | `r meta_all_mod3[["lower.random"]]` | `r meta_all_mod3[["upper.random"]]` | `r meta_all_mod3[["zval.random"]]` | `r meta_all_mod3[["pval.random"]]`


#### Step 3: Run subgroup analyses
##### *Potency (low/high)*
Run sub-analyses by medication potency (low/high) for each model

```{r meta potency subanalysis}
#Model 1
potency_subgroup_mod1 <- update.meta(meta_all_mod1, 
                             byvar=Potency, 
                             comb.random = TRUE, 
                             comb.fixed = FALSE)
#Model 2
potency_subgroup_mod2 <- update.meta(meta_all_mod2, 
                                   byvar=Potency, 
                                   comb.random = TRUE, 
                                   comb.fixed = FALSE)
```
Does not seem to be able to run sub-analysis using REML method:
`Error = Error in rma.uni(yi = TE[sel], sei = seTE[sel], method = method.tau, control = control) :Fisher scoring algorithm did not converge. See 'help(rma)' for possible remedies.`

Code for forest plot (not shown):
```{r meta forest potency mod1, fig.width = 8, fig.height = 13, fig.show = 'hide'}
meta::forest(potency_subgroup_mod1,
             sortvar = TE,
             leftcols = "studlab")
```

Potency = **low**

Model | k | SMD | LL | UL | p-value | tau^2 | Q
------ | ------ | ------ | ------ | ------ | ------| ------ | ------
1 | `r potency_subgroup_mod1[["k.w"]][[1]]` | `r potency_subgroup_mod1[["TE.random.w"]][[1]]` | `r potency_subgroup_mod1[["lower.random.w"]][[1]]` | `r potency_subgroup_mod1[["upper.random.w"]][[1]]` | `r potency_subgroup_mod1[["pval.random.w"]][[1]]` | `r potency_subgroup_mod1[["tau2.w"]][[1]]` | `r potency_subgroup_mod1[["Q.w"]][[1]]`
2 | `r potency_subgroup_mod2[["k.w"]][[1]]` | `r potency_subgroup_mod2[["TE.random.w"]][[1]]` | `r potency_subgroup_mod2[["lower.random.w"]][[1]]` | `r potency_subgroup_mod2[["upper.random.w"]][[1]]` | `r potency_subgroup_mod2[["pval.random.w"]][[1]]` | `r potency_subgroup_mod2[["tau2.w"]][[1]]` | `r potency_subgroup_mod2[["Q.w"]][[1]]`

Potency = **high**

Model | k | SMD | LL | UL | p-value | tau^2 | Q
------ | ------ | ------ | ------ | ------ | ------| ------ | ------
1 | `r potency_subgroup_mod1[["k.w"]][[2]]` | `r potency_subgroup_mod1[["TE.random.w"]][[2]]` | `r potency_subgroup_mod1[["lower.random.w"]][[2]]` | `r potency_subgroup_mod1[["upper.random.w"]][[2]]` | `r potency_subgroup_mod1[["pval.random.w"]][[2]]` | `r potency_subgroup_mod1[["tau2.w"]][[2]]` | `r potency_subgroup_mod1[["Q.w"]][[2]]`
2 | `r potency_subgroup_mod2[["k.w"]][[2]]` | `r potency_subgroup_mod2[["TE.random.w"]][[2]]` | `r potency_subgroup_mod2[["lower.random.w"]][[2]]` | `r potency_subgroup_mod2[["upper.random.w"]][[2]]` | `r potency_subgroup_mod2[["pval.random.w"]][[2]]` | `r potency_subgroup_mod2[["tau2.w"]][[2]]` | `r potency_subgroup_mod2[["Q.w"]][[2]]`

##### *Cognitive domain*

Create data set (`dat_study_domain`) which has the average effect size by cognitive domain within each study.

Cognitive domains were defined using domains outlined by Lezak (2012): 

* Memory
* Executive function
* Attention
* Psychomotor functioning
* Concept formation & reasoning
* Language
* Intelligence
* Perception

Effect sizes based on cognitive composite scores (reported by Stevenson, Robles, Operto) were not included in the cognitive domain sub analysis. 

```{r domain average}
dat_study_domain <- dat %>%
  group_by(study, cog_domain_lezak) %>% #group by study and cognitive domains (based on Lezak) within studies
  mutate(g = mean(g, na.rm = T),
         st_err = mean(st_err, na.rm = T)) %>% #obtain average g and st err within each study/domain
  filter(row_number()==1) %>% #make each study/domain only appear on one row
  filter(cog_domain_lezak != "Not Subdomain") %>% #remove outcomes based on cognitive composite scores
  select(study, author, year, Potency, cog_domain_lezak, g, st_err) #select relevant data
```

Then run random effects model by subgroup (cognitive domain).

**Model 1**

* Use the Sidik-Jonkman method to estimate tau
* Use the Knapp-Hartung method

```{r meta domain mod1, results = 'hide'}
meta_domain_mod1 <- metagen(g,
                    st_err,
                    data = dat_study_domain,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ", #use Sidik-Jonkman method
                    hakn = T, #using the Knapp-Hartung method
                    prediction = T, #True = print prediction interval for future studies based on present evidence
                    sm = "SMD") # says we want to calculate SMD
domain_subgroup_mod1 <- update.meta(meta_domain_mod1, 
                                byvar=cog_domain_lezak, 
                                comb.random = TRUE, 
                                comb.fixed = FALSE)
```

Domain | k | SMD | LL | UL | p
---- | ---- | ---- | ---- | ---- | ---- 
`r domain_subgroup_mod1[["bylevs"]][[1]]` | `r domain_subgroup_mod1[["k.w"]][[1]]` | `r domain_subgroup_mod1[["TE.random.w"]][[1]]` | `r domain_subgroup_mod1[["lower.random.w"]][[1]]` | `r domain_subgroup_mod1[["upper.random.w"]][[1]]` | `r domain_subgroup_mod1[["pval.random.w"]][[1]]`
`r domain_subgroup_mod1[["bylevs"]][[2]]` | `r domain_subgroup_mod1[["k.w"]][[2]]` | `r domain_subgroup_mod1[["TE.random.w"]][[2]]` | `r domain_subgroup_mod1[["lower.random.w"]][[2]]` | `r domain_subgroup_mod1[["upper.random.w"]][[2]]` | `r domain_subgroup_mod1[["pval.random.w"]][[2]]`
`r domain_subgroup_mod1[["bylevs"]][[3]]` | `r domain_subgroup_mod1[["k.w"]][[3]]` | `r domain_subgroup_mod1[["TE.random.w"]][[3]]` | `r domain_subgroup_mod1[["lower.random.w"]][[3]]` | `r domain_subgroup_mod1[["upper.random.w"]][[3]]` | `r domain_subgroup_mod1[["pval.random.w"]][[3]]`
`r domain_subgroup_mod1[["bylevs"]][[4]]` | `r domain_subgroup_mod1[["k.w"]][[4]]` | `r domain_subgroup_mod1[["TE.random.w"]][[4]]` | `r domain_subgroup_mod1[["lower.random.w"]][[4]]` | `r domain_subgroup_mod1[["upper.random.w"]][[4]]` | `r domain_subgroup_mod1[["pval.random.w"]][[4]]`
`r domain_subgroup_mod1[["bylevs"]][[5]]` | `r domain_subgroup_mod1[["k.w"]][[5]]` | `r domain_subgroup_mod1[["TE.random.w"]][[5]]` | `r domain_subgroup_mod1[["lower.random.w"]][[5]]` | `r domain_subgroup_mod1[["upper.random.w"]][[5]]` | `r domain_subgroup_mod1[["pval.random.w"]][[5]]`
`r domain_subgroup_mod1[["bylevs"]][[6]]` | `r domain_subgroup_mod1[["k.w"]][[6]]` | `r domain_subgroup_mod1[["TE.random.w"]][[6]]` | `r domain_subgroup_mod1[["lower.random.w"]][[6]]` | `r domain_subgroup_mod1[["upper.random.w"]][[6]]` | `r domain_subgroup_mod1[["pval.random.w"]][[6]]`
`r domain_subgroup_mod1[["bylevs"]][[7]]` | `r domain_subgroup_mod1[["k.w"]][[7]]` | `r domain_subgroup_mod1[["TE.random.w"]][[7]]` | `r domain_subgroup_mod1[["lower.random.w"]][[7]]` | `r domain_subgroup_mod1[["upper.random.w"]][[7]]` | `r domain_subgroup_mod1[["pval.random.w"]][[7]]`
`r domain_subgroup_mod1[["bylevs"]][[8]]` | `r domain_subgroup_mod1[["k.w"]][[8]]` | `r domain_subgroup_mod1[["TE.random.w"]][[8]]` | `r domain_subgroup_mod1[["lower.random.w"]][[8]]` | `r domain_subgroup_mod1[["upper.random.w"]][[8]]` | `r domain_subgroup_mod1[["pval.random.w"]][[8]]`


Code for forest plot (not shown):
```{r meta forest domain mod1, fig.width = 8, fig.height = 33, fig.show = 'hide'}
meta::forest(domain_subgroup_mod1,
             sortvar = TE,
             leftcols = "studlab")
```

**Model 2**

```{r meta domain mod2}
meta_domain_mod2 <- metagen(g,
                       st_err,
                       data = dat_study_domain,
                       studlab = paste(author, year),
                       comb.fixed = F,
                       comb.random = T,
                       hakn = F, # not using the Knapp-Hartung method
                       prediction = T, #True = print prediction interval for future studies based on present evidence
                       sm = "SMD") # says we want to calculate SMD
domain_subgroup_mod2 <- update.meta(meta_domain_mod2, 
                               byvar=cog_domain_lezak, 
                               comb.random = TRUE, 
                               comb.fixed = FALSE)
```

Code for forest plot (not shown):
```{r meta forest domain mod2, fig.width = 8, fig.height = 33, fig.show = 'hide'}
meta::forest(domain_subgroup_mod2,
             sortvar = TE,
             leftcols = "studlab")
```

Domain | k | SMD | LL | UL | p
---- | ---- | ---- | ---- | ---- | ---- 
`r domain_subgroup_mod2[["bylevs"]][[1]]` | `r domain_subgroup_mod2[["k.w"]][[1]]` | `r domain_subgroup_mod2[["TE.random.w"]][[1]]` | `r domain_subgroup_mod2[["lower.random.w"]][[1]]` | `r domain_subgroup_mod2[["upper.random.w"]][[1]]` | `r domain_subgroup_mod2[["pval.random.w"]][[1]]`
`r domain_subgroup_mod2[["bylevs"]][[2]]` | `r domain_subgroup_mod2[["k.w"]][[2]]` | `r domain_subgroup_mod2[["TE.random.w"]][[2]]` | `r domain_subgroup_mod2[["lower.random.w"]][[2]]` | `r domain_subgroup_mod2[["upper.random.w"]][[2]]` | `r domain_subgroup_mod2[["pval.random.w"]][[2]]`
`r domain_subgroup_mod2[["bylevs"]][[3]]` | `r domain_subgroup_mod2[["k.w"]][[3]]` | `r domain_subgroup_mod2[["TE.random.w"]][[3]]` | `r domain_subgroup_mod2[["lower.random.w"]][[3]]` | `r domain_subgroup_mod2[["upper.random.w"]][[3]]` | `r domain_subgroup_mod2[["pval.random.w"]][[3]]`
`r domain_subgroup_mod2[["bylevs"]][[4]]` | `r domain_subgroup_mod2[["k.w"]][[4]]` | `r domain_subgroup_mod2[["TE.random.w"]][[4]]` | `r domain_subgroup_mod2[["lower.random.w"]][[4]]` | `r domain_subgroup_mod2[["upper.random.w"]][[4]]` | `r domain_subgroup_mod2[["pval.random.w"]][[4]]`
`r domain_subgroup_mod2[["bylevs"]][[5]]` | `r domain_subgroup_mod2[["k.w"]][[5]]` | `r domain_subgroup_mod2[["TE.random.w"]][[5]]` | `r domain_subgroup_mod2[["lower.random.w"]][[5]]` | `r domain_subgroup_mod2[["upper.random.w"]][[5]]` | `r domain_subgroup_mod2[["pval.random.w"]][[5]]`
`r domain_subgroup_mod2[["bylevs"]][[6]]` | `r domain_subgroup_mod2[["k.w"]][[6]]` | `r domain_subgroup_mod2[["TE.random.w"]][[6]]` | `r domain_subgroup_mod2[["lower.random.w"]][[6]]` | `r domain_subgroup_mod2[["upper.random.w"]][[6]]` | `r domain_subgroup_mod2[["pval.random.w"]][[6]]`
`r domain_subgroup_mod2[["bylevs"]][[7]]` | `r domain_subgroup_mod2[["k.w"]][[7]]` | `r domain_subgroup_mod2[["TE.random.w"]][[7]]` | `r domain_subgroup_mod2[["lower.random.w"]][[7]]` | `r domain_subgroup_mod2[["upper.random.w"]][[7]]` | `r domain_subgroup_mod2[["pval.random.w"]][[7]]`
`r domain_subgroup_mod2[["bylevs"]][[8]]` | `r domain_subgroup_mod2[["k.w"]][[8]]` | `r domain_subgroup_mod2[["TE.random.w"]][[8]]` | `r domain_subgroup_mod2[["lower.random.w"]][[8]]` | `r domain_subgroup_mod2[["upper.random.w"]][[8]]` | `r domain_subgroup_mod2[["pval.random.w"]][[8]]`


### Assess publication bias
Steps (based on Amit's paper):

1. Visually inspect funnel plots (effect size vs standard error) for bias
2. **If 10 or more studies**, use Egger's Test to test for small-study effect
    + If statistically significant asymmetry found (1-sided P<0.1), use Duval and Tweedie's Trim and Fill method to quantify magnitude of bias
3. **If <10 studies**, locate outliers in funnel plot and recalculate effect sizes after their removal

To run Egger's, load Egger's function (found [here](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/eggers.test.R))
```{r eggers, include = FALSE}
#' Perform Egger's test of the intercept
#'
#' This function performs Egger's test of the intercept for funnel plot asymmetry using an object
#' of class \code{meta}.
#'
#' @usage eggers.test(x)
#'
#' @param x An object of class \code{meta}, generated by the \code{metabin}, \code{metagen},
#' \code{metacont}, \code{metacor}, \code{metainc}, or \code{metaprop} function.
#'
#' @details Performs Egger's test (Egger et al., 1997) for funnel plot asymmetry.
#' The \code{\link[meta]{metabias}} function is called internally. Egger's test may lack
#' the statistical power to detect bias when the number of studies is small. Sterne et al.
#' (2011) recommend to perform funnel plot asymmetry tests only when \eqn{k \geq 10}. A warning
#' is therefore printed when the number of studies in the \code{meta} object is \eqn{k < 10}.
#'
#' @references
#'
#' Harrer, M., Cuijpers, P., Furukawa, T.A, & Ebert, D. D. (2019).
#' \emph{Doing Meta-Analysis in R: A Hands-on Guide}. DOI: 10.5281/zenodo.2551803. \href{https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/smallstudyeffects.html}{Chapter 9.1}
#'
#' Egger M, Smith GD, Schneider M & Minder C (1997), Bias in meta-analysis detected by a simple,
#' graphical test. \emph{BMJ}, 315, 629–634.
#'
#' Sterne, JAC et al. (2011), Recommendations for Examining and Interpreting Funnel Plot
#' Asymmetry in Meta-Analyses of Randomised Controlled Trials. \emph{BMJ}
#' 343, 1, doi: 10.1136/bmj.d4002 .
#'
#' @author Mathias Harrer & David Daniel Ebert
#'
#' @importFrom meta metabias
#' @importFrom graphics abline axis lines mtext par plot points rect segments text
#' @importFrom stats as.formula hat influence ks.test optimize pbinom pchisq pf pnorm pt punif qchisq qf qnorm qt reformulate reorder setNames uniroot
#'
#' @return Returns a data.frame containing the following columns:
#' \itemize{
#' \item \code{Intercept}: The intercept (bias).
#' \item \code{ConfidenceInterval}: The 95\% confidence interval of the intercept.
#' \item \code{t}: The t-statistic for the intercept test.
#' \item \code{p}: The \eqn{p}-value for Egger's test.
#' }
#'
#' @export eggers.test
#'
#' @seealso \code{\link[meta]{metabias}}
#'
#' @examples
#' # Create meta-analysis results using the 'metagen' function
#' suppressPackageStartupMessages(library(meta))
#' data(ThirdWave)
#' m = metagen(TE, seTE, studlab = paste(Author),
#'     data = ThirdWave, comb.random = FALSE, hakn=TRUE)
#'
#' # Plug result into 'eggers.test' function
#' eggers.test(m)


eggers.test = function(x) {

    # Validate
    x = x

    if (x$k < 10) {

        warning(paste("Your meta-analysis contains k =", x$k, "studies. Egger's test may lack the statistical power to detect bias when the number of studies is small (i.e., k<10)."))

    }

    if (class(x)[1] %in% c("meta", "metabin", "metagen", "metacont", "metacor", "metainc", "metaprop")) {

        # Conduct metabias
        eggers = meta::metabias(x, k.min = 3, method = "linreg")

        # Get Intercept
        intercept = as.numeric(eggers$estimate[1]) %>% round(digits = 3)

        # Get SE
        se = as.numeric(eggers$estimate[2])

        # Calculate 95CI
        LLCI = intercept - 1.96 * se %>% round(digits = 1)
        ULCI = intercept + 1.96 * se %>% round(digits = 1)
        CI = paste(LLCI, "-", ULCI, sep = "")

        # Get t
        t = as.numeric(eggers$statistic) %>% round(digits = 3)

        # Get df
        df = as.numeric(eggers$parameters)

        # Get p
        p = as.numeric(eggers$p.value) %>% round(digits = 5)

        # Make df
        df = data.frame(Intercept = intercept, ConfidenceInterval = CI, t = t, p = p)
        row.names(df) = "Egger's test"

    } else {

        stop("x must be of type 'metabin', 'metagen', 'metacont', 'metainc' or 'metaprop'")

    }

    return(df)

}


```

Note: it does not matter which meta-analysis model the funnel plot or Egger's test are conducted based on, as only the individual study effect sizes matter, not the pooled effect size.
HOWEVER, models must be run separately for Trim and Fill.

#### Whole meta-analysis
```{r meta funnel whole}
funnel.meta(meta_all_mod1)
```

```{r meta eggers whole}
eggers.test(x = meta_all_mod1)
```

p<0.1, therefore Duval and Tweedie's trim and fill method was used to quantify the magnitude of bias.

```{r meta trimfill whole, results = 'hide'}
meta_all_mod1_trim <- trimfill.meta(meta_all_mod1)
meta_all_mod2_trim <- trimfill.meta(meta_all_mod2)
```

```{r meta funnel trimfill whole}
funnel.meta(meta_all_mod1_trim)
funnel.meta(meta_all_mod2_trim)
```

Results of trim and fill analysis (with 12 studies imputed)

Model | SMD | LL | UL | t (mod1)/z (mod 2) | p-value
------ | ------ | ------ | ------ | ------ | ------
1 | `r meta_all_mod1_trim[["TE.random"]]` |`r meta_all_mod1_trim[["lower.random"]]` | `r meta_all_mod1_trim[["upper.random"]]` | `r meta_all_mod1_trim[["zval.random"]]` | `r meta_all_mod1_trim[["pval.random"]]`
2 | `r meta_all_mod2_trim[["TE.random"]]` | `r meta_all_mod2_trim[["lower.random"]]` | `r meta_all_mod2_trim[["upper.random"]]` | `r meta_all_mod2_trim[["zval.random"]]` | `r meta_all_mod2_trim[["pval.random"]]`

#### Potency
Does not seem possible to plot (using funnel plots) the individual parts of the sub-analyses separately. So, first I will run the meta-analyses separately for each subgroup (code not shown). This will provide the same results as previously found, it just requires extra data wrangling (filtering by subgroup), and more code. 

```{r potency subanalysis, include = FALSE}
dat_pot_low <-dat_study %>%
  filter(Potency == "Low")

meta_low_mod1 <- metagen(g,
                    st_err,
                    data = dat_pot_low,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")

meta_low_mod2 <- metagen(g,
                    st_err,
                    data = dat_pot_low,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")

dat_pot_high <-dat_study %>%
  filter(Potency == "High")

meta_high_mod1 <- metagen(g,
                    st_err,
                    data = dat_pot_high,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")

meta_high_mod2 <- metagen(g,
                    st_err,
                    data = dat_pot_high,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
```

**Low potency**
```{r meta funnel low potency}
funnel.meta(meta_low_mod1)
```

Egger's:
```{r meta eggers low potency}
eggers.test(x = meta_low_mod1)
```

P>0.1 so nothing further required, no indication of substantial publication bias.



**High potency**
```{r meta funnel high potency}
funnel.meta(meta_high_mod1)
```

Egger's:
```{r meta eggers high potency}
eggers.test(x = meta_high_mod1)
```

p<0.1, therefore Duval and Tweedie's trim and fill method was used to quantify the magnitude of bias.

```{r meta trimfill high potency, results = 'hide'}
meta_high_mod1_trim <- trimfill.meta(meta_high_mod1)
meta_high_mod2_trim <- trimfill.meta(meta_high_mod2)
```

```{r meta funnel trimfill high potency}
funnel.meta(meta_high_mod1_trim)
funnel.meta(meta_high_mod2_trim)
```

Results of trim and fill analysis (with **XX** studies imputed)

Model | SMD | LL | UL | t (mod1)/z (mod 2) | p-value
------ | ------ | ------ | ------ | ------ | ------
1 | `r meta_high_mod1_trim[["TE.random"]]` |`r meta_high_mod1_trim[["lower.random"]]` | `r meta_high_mod1_trim[["upper.random"]]` | `r meta_high_mod1_trim[["zval.random"]]` | `r meta_high_mod1_trim[["pval.random"]]`
2 | `r meta_high_mod2_trim[["TE.random"]]` | `r meta_high_mod2_trim[["lower.random"]]` | `r meta_high_mod2_trim[["upper.random"]]` | `r meta_high_mod2_trim[["zval.random"]]` | `r meta_high_mod2_trim[["pval.random"]]`



#### Cognitive domains
Again, run subgroup analyses individually first (code not displayed).

```{r domain subanalysis, include=FALSE}
#attention
dat_dom_att <- dat_study_domain %>%
  filter(cog_domain_lezak == "Attention")
meta_att_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_att,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_att_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_att,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#memory
dat_dom_mem <- dat_study_domain %>%
  filter(cog_domain_lezak == "Memory")
meta_mem_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_mem,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_mem_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_mem,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#executive function
dat_dom_exec <- dat_study_domain %>%
  filter(cog_domain_lezak == "Executive Function")
meta_exec_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_exec,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_exec_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_exec,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#psychomotor functioning
dat_dom_psych <- dat_study_domain %>%
  filter(cog_domain_lezak == "Psychomotor Functioning")
meta_psych_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_psych,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_psych_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_psych,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#Concept formation & reasoning
dat_dom_conc <- dat_study_domain %>%
  filter(cog_domain_lezak == "Concept Formation & Reasoning")
meta_conc_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_conc,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_conc_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_conc,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#Language
dat_dom_lang <- dat_study_domain %>%
  filter(cog_domain_lezak == "Language")
meta_lang_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_lang,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_lang_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_lang,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#Intelligence (General)
dat_dom_gen <- dat_study_domain %>%
  filter(cog_domain_lezak == "General")
meta_gen_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_gen,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_gen_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_gen,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#Perception
dat_dom_perc <- dat_study_domain %>%
  filter(cog_domain_lezak == "Perception")
meta_perc_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_perc,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_perc_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_perc,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
```

**Attention**
```{r meta funnel attention}
funnel.meta(meta_att_mod1)
```

Egger's:
```{r meta eggers attention}
eggers.test(x = meta_att_mod1)
```

P>0.1 so nothing further required, no indication of substantial publication bias



**Memory**
```{r meta funnel memory}
funnel.meta(meta_mem_mod1)
```

Egger's:
```{r meta eggers memory}
eggers.test(x = meta_mem_mod1)
```

P>0.1 so nothing further required, no indication of substantial publication bias



**Executive function**
```{r meta funnel executive}
funnel.meta(meta_exec_mod1)
```

Egger's:
```{r meta eggers executive}
eggers.test(x = meta_exec_mod1)
```

P>0.1 so nothing further required, no indication of substantial publication bias



**Psychomotor functioning**
```{r meta funnel psychomotor}
funnel.meta(meta_psych_mod1)
```

Egger's:
```{r meta eggers psychomotor}
eggers.test(x = meta_psych_mod1)
```

p<0.1, therefore Duval and Tweedie's trim and fill method was used to quantify the magnitude of bias.

```{r meta trimfill psychomotor, results = 'hide'}
meta_psych_mod1_trim <- trimfill.meta(meta_psych_mod1)
meta_psych_mod2_trim <- trimfill.meta(meta_psych_mod2)
```

```{r meta funnel trimfill psychomotor}
funnel.meta(meta_psych_mod1_trim)
funnel.meta(meta_psych_mod2_trim)
```

Results of trim and fill analysis (with **XX** studies imputed)

Model | SMD | LL | UL | t (mod1)/z (mod 2) | p-value
------ | ------ | ------ | ------ | ------ | ------
1 | `r meta_psych_mod1_trim[["TE.random"]]` |`r meta_psych_mod1_trim[["lower.random"]]` | `r meta_psych_mod1_trim[["upper.random"]]` | `r meta_psych_mod1_trim[["zval.random"]]` | `r meta_psych_mod1_trim[["pval.random"]]`
2 | `r meta_psych_mod2_trim[["TE.random"]]` | `r meta_psych_mod2_trim[["lower.random"]]` | `r meta_psych_mod2_trim[["upper.random"]]` | `r meta_psych_mod2_trim[["zval.random"]]` | `r meta_psych_mod2_trim[["pval.random"]]`

**DECIDE WHETHER TO PRINT THE RESULTS PRE TRIM AND FILL NEXT TO THIS AS WELL**



**Concept formation**
```{r meta funnel concept}
funnel.meta(meta_conc_mod1)
```

Egger's:
```{r meta eggers concept}
eggers.test(x = meta_conc_mod1)
```

**FURTHER ACTION REQUIRED**



**Language**
```{r meta funnel language}
funnel.meta(meta_lang_mod1)
```

<10 studies so Egger's not done

**FURTHER ACTION - assess visually for outliers**



**General**
```{r meta funnel general}
funnel.meta(meta_gen_mod1)
```

Egger's:
```{r meta eggers general}
eggers.test(x = meta_gen_mod1)
```

**FURTHER ACTION REQUIRED**



**Perception**
```{r meta funnel perception}
funnel.meta(meta_perc_mod1)
```

<10 studies so Egger's not done

**FURTHER ACTION - assess visually for outliers**

### Models in metafor
To contrast with analyses in the `meta` package, we will now also run analyses in the `metafor` package. Upon initial inspection, I noticed the I^2 value was different early in conducting these analyses. I want to ensure we choose the correct package.

Notes from the book: First, the amount of (residual) heterogeneity (i.e., τ2) is estimated with one of the various estimators that have been suggested in the literaturen (e.g. Hunter-Schmidt, Hedges estimator, DerSimonian-Laird estimator, Sidik-Jonkman estimator, maximum-likelihood or restricted maximum-likelihood estimator, empirical Bayes estimator)

#### Step 1: Load the package
```{r load metafor}
library(metafor)
```

#### Step 2: Run the random-effects model
`metafor` asks for the sampling variance via the `vi` argument. However, we have the standard error (square root of the variances), which can be supplied via the `sei` argument. When specifying the data in this way, we **must** set `measure = "GEN"` (Which is the default).

REML estimator is the default t^2 estimator. The various (residual) heterogeneity measures that can be specified via the `method` argument are the:

* "HS" = Hunter-Schmidt estimator
* "HE" = Hedges estimator
* "DL" = DerSimonian-Laird estimator
* "SJ" = Sidik-Jonkman estimator
* "ML" = Maximum-likelihood estimator
* "REML" = Restricted maximum-likelihood estimator
* "EB" = Empirical Bayes estimator

*Knapp and Hartung adjustment*

By default, the test statistics of the individual coefficients in the model (and the corresponding confidence intervals) are based on the normal distribution, while the omnibus test is based on a χ2 distribution with m degrees of freedom (m being the number of coefficients tested). The Knapp and Hartung (2003) method (`knha = TRUE`) is an adjustment to the standard errors of the estimated coefficients, which helps to account for the uncertainty in the estimate of τ2 and leads to different reference distributions. Individual coefficients and confidence intervals are then based on the t-distribution with k − p degrees of freedom, while the omnibus test statistic then uses an F-distribution with m and k − p degrees of freedom (p being the total number of model coefficients including the intercept if it is present). The Knapp and Hartung adjustment is only meant to be used in the context of random- or mixed-effects model.

**Model 1**

* Use the Sidik-Jonkman method to estimate tau
* Use the Knapp-Hartung method

```{r metafor whole mod1, fig.width = 4}
metafor_whole_mod1 <- rma(yi = g, 
                          sei = st_err, 
                          data = dat_study,
                          method = "SJ",
                          knha = TRUE)
```

**Model 2**

* Use the DerSimonian-Laird estimator method to estimate tau
* Not using the Knapp-Hartung method

```{r metafor whole mod2}
metafor_whole_mod2 <- rma(yi = g, 
                          sei = st_err, 
                          data = dat_study,
                          method = "DL",
                          knha = FALSE)
```

**Model 3**

* Use the DerSimonian-Laird estimator method to estimate tau
* Use the Knapp-Hartung method

```{r metafor whole mod3}
metafor_whole_mod3 <- rma(yi = g, 
                          sei = st_err, 
                          data = dat_study,
                          method = "DL",
                          knha = TRUE)
```

**Model 4**

* Use the Restricted maximum-likelihood estimator method to estimate tau
* Use the Knapp-Hartung method

```{r metafor whole mod4}
metafor_whole_mod4 <- rma(yi = g, 
                          sei = st_err, 
                          data = dat_study,
                          method = "REML",
                          knha = TRUE)
```
**meta**

Model | k | SMD | LL | UL | z or t val | p | I^2
------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ 
1 | `r meta_all_mod1[["k"]]` |`r meta_all_mod1[["TE.random"]]` |`r meta_all_mod1[["lower.random"]]` | `r meta_all_mod1[["upper.random"]]` | `r meta_all_mod1[["zval.random"]]` | `r meta_all_mod1[["pval.random"]]` | `r meta_all_mod1[["I2"]]`
2 | `r meta_all_mod2[["k"]]` | `r meta_all_mod2[["TE.random"]]` | `r meta_all_mod2[["lower.random"]]` | `r meta_all_mod2[["upper.random"]]` | `r meta_all_mod2[["zval.random"]]` | `r meta_all_mod2[["pval.random"]]` | `r meta_all_mod2[["I2"]]`
3 | `r meta_all_mod3[["k"]]` | `r meta_all_mod3[["TE.random"]]` | `r meta_all_mod3[["lower.random"]]` | `r meta_all_mod3[["upper.random"]]` | `r meta_all_mod3[["zval.random"]]` | `r meta_all_mod3[["pval.random"]]` | `r meta_all_mod3[["I2"]]`



**metafor**

Model | k | estimate | LL | UL | z or tval | p | I^2
------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ 
1 | `r metafor_whole_mod1[["k"]]` | `r metafor_whole_mod1[["b"]]` |  `r metafor_whole_mod1[["ci.lb"]]` | `r metafor_whole_mod1[["ci.ub"]]` | `r metafor_whole_mod1[["zval"]]` | `r metafor_whole_mod1[["pval"]]` | `r metafor_whole_mod1[["I2"]]`
2 | `r metafor_whole_mod2[["k"]]` | `r metafor_whole_mod2[["b"]]` |  `r metafor_whole_mod2[["ci.lb"]]` | `r metafor_whole_mod2[["ci.ub"]]` | `r metafor_whole_mod2[["zval"]]` | `r metafor_whole_mod2[["pval"]]` | `r metafor_whole_mod2[["I2"]]`
3 | `r metafor_whole_mod3[["k"]]` | `r metafor_whole_mod3[["b"]]` |  `r metafor_whole_mod3[["ci.lb"]]` | `r metafor_whole_mod3[["ci.ub"]]` | `r metafor_whole_mod3[["zval"]]` | `r metafor_whole_mod3[["pval"]]` | `r metafor_whole_mod3[["I2"]]`
4 | `r metafor_whole_mod4[["k"]]` | `r metafor_whole_mod4[["b"]]` |  `r metafor_whole_mod4[["ci.lb"]]` | `r metafor_whole_mod4[["ci.ub"]]` | `r metafor_whole_mod4[["zval"]]` | `r metafor_whole_mod4[["pval"]]` | `r metafor_whole_mod4[["I2"]]`

##### Subgroup: Potency
**Low**
```{r metafor low potency mod1}
metafor_lowpot_mod1 <- rma(yi = g, 
                          sei = st_err, 
                          data = dat_study,
                          method = "SJ",
                          knha = TRUE,
                          subset = (Potency=="Low"))
```

#### Step 3: Publication bias
```{r metafor funnel whole}
metafor::funnel(metafor_whole_mod1)
```

regression test (Eggers? but gave different results to one done through meta: Conducting meta-analyses in R with the metafor package)
```{r metafor regtest whole mod1}
regtest(metafor_whole_mod1)
```

Test trim and fill method
```{r metafor trimfill whole}
trim <- metafor::trimfill(metafor_whole_mod1, estimator = "R0", side = NULL)
trim

```

### Results section
Based on metafor SJ knapp model

**Overall cognition:**

Overall, `r metafor_whole_mod1[["k"]]` studies reporting **x** effect sizes were available for analysis. The effect size of the difference between cognition “on” and “off” anticholinergic medication across the `r metafor_whole_mod1[["k"]]` studies was null (Hedges’ g = `r metafor_whole_mod1[["b"]]`, 95% confidence interval (CI): `r metafor_whole_mod1[["ci.lb"]]` to `r metafor_whole_mod1[["ci.ub"]]`, p = `r metafor_whole_mod1[["pval"]]`; see Figure X), with (null/low/mod/high) heterogeneity between studies (T2 = X, I2 = X%). The funnel plot did/did not reveal a potential small study effect (Egger’s intercept = X, one-tailed p=X; see Figure X).
Subgroup analysis:
Potency. The difference between “on” and “off” medication cognitive performance when considering attention (k=X, g= X, 95%CI: X to X), … , were not significantly different across these domains?

