---
title: "Anticholinergic Meta analysis"
output: 
  html_document:
    keep_md: true
---

### Load packages
```{r setup, results = 'hide', message = FALSE}
library(meta)
library(tidyverse)
```

### Data import
Import data (.csv) 
```{r data import, results = 'hide', warning = FALSE, message = FALSE}
library(readr)
Anticholinergic_Medication_R_data <- read_csv("Z:/PROJECTS/2018_Anticholinergic_Med_SR/Analysis/Anticholinergic_Medication_R_data.csv")
```

Assign data to `dat`
```{r assign dat}
dat <- Anticholinergic_Medication_R_data
```

### Meta-analysis
#### Step 1: Average across studies
This step is necessary to ensure independence of each effect size entered into the meta-analysis. In the current form, most studies report multiple outcomes (time-points, medication, cognitive tests), and these results are dependent on each other, as they come from they come from overlapping samples of participants. 

Data are averaged **within studies** so that each study represents a single effect size.
In all cases of studies which included outcomes for different medications, all medications were either low or high potency, so outcomes were able averaged together (within the study).

Averaged results are assigned to `dat_study`

```{r study average}
dat_study <- dat %>%
  group_by(study) %>% #group by study so further calculations are done within each study
  mutate(g = mean(g, na.rm = T),
          st_err = mean(st_err, na.rm = T)) %>% #obtain average g and st err within each study, removing NAs from calculation
  filter(row_number()==1) %>% #make each study only appear on one row
  select(study, author, year, Potency, g, st_err) #select relevant data for analysis
```

#### Step 2: Run random effects model of all data
**Model 1**

* Use the Sidik-Jonkman method to estimate tau
* Use the Knapp-Hartung method

```{r model 1, results = 'hide'}
meta_all_mod1 <- metagen(g,
                    st_err,
                    data = dat_study,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ", #use Sidik-Jonkman method
                    hakn = T, #using the Knapp-Hartung method
                    prediction = T, #True = print prediction interval for future studies based on present evidence
                    sm = "SMD") # says we want to calculate SMD
```

Code for forest plot:
```{r forest mod1, fig.width=8, fig.height=12}
meta::forest(meta_all_mod1,
             sortvar = TE,
             xlim = c(-1.5, 1.5),
             leftcols = "studlab",
             rightcols = c("TE", "ci"),
             rightlabs = c("SMD", "95% CI"),
             text.random = "Overall effect") #found this here: https://rdrr.io/cran/meta/man/forest.html
```

**Model 2**

* Use the DerSimonian-Laird method (default) to estimate tau
* Do not use Knapp-Hartung method

```{r model 2, results = 'hide'}
meta_all_mod2 <- metagen(g,
                          st_err,
                          data = dat_study,
                          studlab = paste(author, year),
                          comb.fixed = F,
                          comb.random = T,
                          hakn = F, # not using the Knapp-Hartung method
                          prediction = T, #True = print prediction interval for future studies based on present evidence
                          sm = "SMD")
```

Code for forest plot (not displayed):
```{r forest mod2, fig.width=8, fig.height=12, fig.show = 'hide'}
meta::forest(meta_all_mod2,
             sortvar = TE,
             xlim = c(-1.5, 1.5),
             leftcols = "studlab") #found this here: https://rdrr.io/cran/meta/man/forest.html
```

**Model 3**

* Use the Restricted Maximum-Likelihood method to estimate tau
* Not using Knapp-Hartung method

```{r model 3, results = 'hide'}
meta_all_mod3 <- metagen(g,
                          st_err,
                          data = dat_study,
                          studlab = paste(author, year),
                          comb.fixed = F,
                          comb.random = T,
                          method.tau = "REML",
                          hakn = F, # not using the Knapp-Hartung method
                          prediction = T, #True = print prediction interval for future studies based on present evidence
                          sm = "SMD")
```

Code for forest plot (not displayed):
```{r forest mod3, fig.width=8, fig.height=12, fig.show = 'hide'}
meta::forest(meta_all_mod2,
             sortvar = TE,
             xlim = c(-1.5, 1.5),
             leftcols = "studlab") #found this here: https://rdrr.io/cran/meta/man/forest.html
```

Compare the models:

Model | SMD | LL | UL | t (mod1)/z (mod 2) | p-value
------ | ------ | ------ | ------ | ------ | ------
1 | `r meta_all_mod1[["TE.random"]]` |`r meta_all_mod1[["lower.random"]]` | `r meta_all_mod1[["upper.random"]]` | `r meta_all_mod1[["zval.random"]]` | `r meta_all_mod1[["pval.random"]]`
2 | `r meta_all_mod2[["TE.random"]]` | `r meta_all_mod2[["lower.random"]]` | `r meta_all_mod2[["upper.random"]]` | `r meta_all_mod2[["zval.random"]]` | `r meta_all_mod2[["pval.random"]]`
3 | `r meta_all_mod3[["TE.random"]]` | `r meta_all_mod3[["lower.random"]]` | `r meta_all_mod3[["upper.random"]]` | `r meta_all_mod3[["zval.random"]]` | `r meta_all_mod3[["pval.random"]]`


#### Step 3: Run subgroup analyses
*##### Potency (low/high)*
Run sub-analyses by medication potency (low/high) for each model

```{r potency subanalysis}
potency_subgroup_mod1 <- update.meta(meta_all_mod1, 
                             byvar=Potency, 
                             comb.random = TRUE, 
                             comb.fixed = FALSE)
potency_subgroup_mod2 <- update.meta(meta_all_mod2, 
                                   byvar=Potency, 
                                   comb.random = TRUE, 
                                   comb.fixed = FALSE)
```
Does not seem to be able to run sub-analysis using REML method:
Error = Error in rma.uni(yi = TE[sel], sei = seTE[sel], method = method.tau, control = control) : Fisher scoring algorithm did not converge. See 'help(rma)' for possible remedies.

Code for forest plot (not shown):
```{r model 1 potency forest, fig.width = 8, fig.height = 13, fig.show = 'hide'}
meta::forest(potency_subgroup_mod1,
             sortvar = TE,
             leftcols = "studlab")
```

Potency = **low**

Model | k | SMD | LL | UL | p-value | tau^2 | Q
------ | ------ | ------ | ------ | ------ | ------| ------ | ------
1 | `r potency_subgroup_mod1[["k.w"]][[1]]` | `r potency_subgroup_mod1[["TE.random.w"]][[1]]` | `r potency_subgroup_mod1[["lower.random.w"]][[1]]` | `r potency_subgroup_mod1[["upper.random.w"]][[1]]` | `r potency_subgroup_mod1[["pval.random.w"]][[1]]` | `r potency_subgroup_mod1[["tau2.w"]][[1]]` | `r potency_subgroup_mod1[["Q.w"]][[1]]`
2 | `r potency_subgroup_mod2[["k.w"]][[1]]` | `r potency_subgroup_mod2[["TE.random.w"]][[1]]` | `r potency_subgroup_mod2[["lower.random.w"]][[1]]` | `r potency_subgroup_mod2[["upper.random.w"]][[1]]` | `r potency_subgroup_mod2[["pval.random.w"]][[1]]` | `r potency_subgroup_mod2[["tau2.w"]][[1]]` | `r potency_subgroup_mod2[["Q.w"]][[1]]`

Potency = **high**

Model | k | SMD | LL | UL | p-value | tau^2 | Q
------ | ------ | ------ | ------ | ------ | ------| ------ | ------
1 | `r potency_subgroup_mod1[["k.w"]][[2]]` | `r potency_subgroup_mod1[["TE.random.w"]][[2]]` | `r potency_subgroup_mod1[["lower.random.w"]][[2]]` | `r potency_subgroup_mod1[["upper.random.w"]][[2]]` | `r potency_subgroup_mod1[["pval.random.w"]][[2]]` | `r potency_subgroup_mod1[["tau2.w"]][[2]]` | `r potency_subgroup_mod1[["Q.w"]][[2]]`
2 | `r potency_subgroup_mod2[["k.w"]][[2]]` | `r potency_subgroup_mod2[["TE.random.w"]][[2]]` | `r potency_subgroup_mod2[["lower.random.w"]][[2]]` | `r potency_subgroup_mod2[["upper.random.w"]][[2]]` | `r potency_subgroup_mod2[["pval.random.w"]][[2]]` | `r potency_subgroup_mod2[["tau2.w"]][[2]]` | `r potency_subgroup_mod2[["Q.w"]][[2]]`

*##### Cognitive domain*

Create data set (`dat_study_domain`) which has the average effect size by cognitive domain within each study.

Cognitive domains were defined using domains outlined by Lezak (2012): 

* Memory
* Executive function
* Attention
* Psychomotor functioning
* Concept formation & reasoning
* Language
* Intelligence
* Perception

Effect sizes based on cognitive composite scores (reported by Stevenson, Robles, Operto) were not included in the cognitive domain sub analysis. 

```{r domain average}
dat_study_domain <- dat %>%
  group_by(study, cog_domain_lezak) %>% #group by study and cognitive domains (based on Lezak) within studies
  mutate(g = mean(g, na.rm = T),
         st_err = mean(st_err, na.rm = T)) %>% #obtain average g and st err within each study/domain
  filter(row_number()==1) %>% #make each study/domain only appear on one row
  filter(cog_domain_lezak != "Not Subdomain") %>% #remove outcomes based on cognitive composite scores
  select(study, author, year, Potency, cog_domain_lezak, g, st_err) #select relevant data
```

Then run random effects model by subgroup (cognitive domain).

**Model 1**

* Use the Sidik-Jonkman method to estimate tau
* Use the Knapp-Hartung method

```{r model 1 domain, results = 'hide'}
meta_domain_mod1 <- metagen(g,
                    st_err,
                    data = dat_study_domain,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ", #use Sidik-Jonkman method
                    hakn = T, #using the Knapp-Hartung method
                    prediction = T, #True = print prediction interval for future studies based on present evidence
                    sm = "SMD") # says we want to calculate SMD
domain_subgroup_mod1 <- update.meta(meta_domain_mod1, 
                                byvar=cog_domain_lezak, 
                                comb.random = TRUE, 
                                comb.fixed = FALSE)
```

Domain | k | SMD | LL | UL | p
---- | ---- | ---- | ---- | ---- | ---- 
`r domain_subgroup_mod1[["bylevs"]][[1]]` | `r domain_subgroup_mod1[["k.w"]][[1]]` | `r domain_subgroup_mod1[["TE.random.w"]][[1]]` | `r domain_subgroup_mod1[["lower.random.w"]][[1]]` | `r domain_subgroup_mod1[["upper.random.w"]][[1]]` | `r domain_subgroup_mod1[["pval.random.w"]][[1]]`
`r domain_subgroup_mod1[["bylevs"]][[2]]` | `r domain_subgroup_mod1[["k.w"]][[2]]` | `r domain_subgroup_mod1[["TE.random.w"]][[2]]` | `r domain_subgroup_mod1[["lower.random.w"]][[2]]` | `r domain_subgroup_mod1[["upper.random.w"]][[2]]` | `r domain_subgroup_mod1[["pval.random.w"]][[2]]`
`r domain_subgroup_mod1[["bylevs"]][[3]]` | `r domain_subgroup_mod1[["k.w"]][[3]]` | `r domain_subgroup_mod1[["TE.random.w"]][[3]]` | `r domain_subgroup_mod1[["lower.random.w"]][[3]]` | `r domain_subgroup_mod1[["upper.random.w"]][[3]]` | `r domain_subgroup_mod1[["pval.random.w"]][[3]]`
`r domain_subgroup_mod1[["bylevs"]][[4]]` | `r domain_subgroup_mod1[["k.w"]][[4]]` | `r domain_subgroup_mod1[["TE.random.w"]][[4]]` | `r domain_subgroup_mod1[["lower.random.w"]][[4]]` | `r domain_subgroup_mod1[["upper.random.w"]][[4]]` | `r domain_subgroup_mod1[["pval.random.w"]][[4]]`
`r domain_subgroup_mod1[["bylevs"]][[5]]` | `r domain_subgroup_mod1[["k.w"]][[5]]` | `r domain_subgroup_mod1[["TE.random.w"]][[5]]` | `r domain_subgroup_mod1[["lower.random.w"]][[5]]` | `r domain_subgroup_mod1[["upper.random.w"]][[5]]` | `r domain_subgroup_mod1[["pval.random.w"]][[5]]`
`r domain_subgroup_mod1[["bylevs"]][[6]]` | `r domain_subgroup_mod1[["k.w"]][[6]]` | `r domain_subgroup_mod1[["TE.random.w"]][[6]]` | `r domain_subgroup_mod1[["lower.random.w"]][[6]]` | `r domain_subgroup_mod1[["upper.random.w"]][[6]]` | `r domain_subgroup_mod1[["pval.random.w"]][[6]]`
`r domain_subgroup_mod1[["bylevs"]][[7]]` | `r domain_subgroup_mod1[["k.w"]][[7]]` | `r domain_subgroup_mod1[["TE.random.w"]][[7]]` | `r domain_subgroup_mod1[["lower.random.w"]][[7]]` | `r domain_subgroup_mod1[["upper.random.w"]][[7]]` | `r domain_subgroup_mod1[["pval.random.w"]][[7]]`
`r domain_subgroup_mod1[["bylevs"]][[8]]` | `r domain_subgroup_mod1[["k.w"]][[8]]` | `r domain_subgroup_mod1[["TE.random.w"]][[8]]` | `r domain_subgroup_mod1[["lower.random.w"]][[8]]` | `r domain_subgroup_mod1[["upper.random.w"]][[8]]` | `r domain_subgroup_mod1[["pval.random.w"]][[8]]`


Code for forest plot (not shown):
```{r model 1 domain forest, fig.width = 8, fig.height = 33, fig.show = 'hide'}
meta::forest(domain_subgroup_mod1,
             sortvar = TE,
             leftcols = "studlab")
```

**Model 2**

```{r model 2 domain}
meta_domain_mod2 <- metagen(g,
                       st_err,
                       data = dat_study_domain,
                       studlab = paste(author, year),
                       comb.fixed = F,
                       comb.random = T,
                       hakn = F, # not using the Knapp-Hartung method
                       prediction = T, #True = print prediction interval for future studies based on present evidence
                       sm = "SMD") # says we want to calculate SMD
domain_subgroup_mod2 <- update.meta(meta_domain_mod2, 
                               byvar=cog_domain_lezak, 
                               comb.random = TRUE, 
                               comb.fixed = FALSE)
```

Code for forest plot (not shown):
```{r model 2 domain forest, fig.width = 8, fig.height = 33, fig.show = 'hide'}
meta::forest(domain_subgroup_mod2,
             sortvar = TE,
             leftcols = "studlab")
```

Domain | k | SMD | LL | UL | p
---- | ---- | ---- | ---- | ---- | ---- 
`r domain_subgroup_mod2[["bylevs"]][[1]]` | `r domain_subgroup_mod2[["k.w"]][[1]]` | `r domain_subgroup_mod2[["TE.random.w"]][[1]]` | `r domain_subgroup_mod2[["lower.random.w"]][[1]]` | `r domain_subgroup_mod2[["upper.random.w"]][[1]]` | `r domain_subgroup_mod2[["pval.random.w"]][[1]]`
`r domain_subgroup_mod2[["bylevs"]][[2]]` | `r domain_subgroup_mod2[["k.w"]][[2]]` | `r domain_subgroup_mod2[["TE.random.w"]][[2]]` | `r domain_subgroup_mod2[["lower.random.w"]][[2]]` | `r domain_subgroup_mod2[["upper.random.w"]][[2]]` | `r domain_subgroup_mod2[["pval.random.w"]][[2]]`
`r domain_subgroup_mod2[["bylevs"]][[3]]` | `r domain_subgroup_mod2[["k.w"]][[3]]` | `r domain_subgroup_mod2[["TE.random.w"]][[3]]` | `r domain_subgroup_mod2[["lower.random.w"]][[3]]` | `r domain_subgroup_mod2[["upper.random.w"]][[3]]` | `r domain_subgroup_mod2[["pval.random.w"]][[3]]`
`r domain_subgroup_mod2[["bylevs"]][[4]]` | `r domain_subgroup_mod2[["k.w"]][[4]]` | `r domain_subgroup_mod2[["TE.random.w"]][[4]]` | `r domain_subgroup_mod2[["lower.random.w"]][[4]]` | `r domain_subgroup_mod2[["upper.random.w"]][[4]]` | `r domain_subgroup_mod2[["pval.random.w"]][[4]]`
`r domain_subgroup_mod2[["bylevs"]][[5]]` | `r domain_subgroup_mod2[["k.w"]][[5]]` | `r domain_subgroup_mod2[["TE.random.w"]][[5]]` | `r domain_subgroup_mod2[["lower.random.w"]][[5]]` | `r domain_subgroup_mod2[["upper.random.w"]][[5]]` | `r domain_subgroup_mod2[["pval.random.w"]][[5]]`
`r domain_subgroup_mod2[["bylevs"]][[6]]` | `r domain_subgroup_mod2[["k.w"]][[6]]` | `r domain_subgroup_mod2[["TE.random.w"]][[6]]` | `r domain_subgroup_mod2[["lower.random.w"]][[6]]` | `r domain_subgroup_mod2[["upper.random.w"]][[6]]` | `r domain_subgroup_mod2[["pval.random.w"]][[6]]`
`r domain_subgroup_mod2[["bylevs"]][[7]]` | `r domain_subgroup_mod2[["k.w"]][[7]]` | `r domain_subgroup_mod2[["TE.random.w"]][[7]]` | `r domain_subgroup_mod2[["lower.random.w"]][[7]]` | `r domain_subgroup_mod2[["upper.random.w"]][[7]]` | `r domain_subgroup_mod2[["pval.random.w"]][[7]]`
`r domain_subgroup_mod2[["bylevs"]][[8]]` | `r domain_subgroup_mod2[["k.w"]][[8]]` | `r domain_subgroup_mod2[["TE.random.w"]][[8]]` | `r domain_subgroup_mod2[["lower.random.w"]][[8]]` | `r domain_subgroup_mod2[["upper.random.w"]][[8]]` | `r domain_subgroup_mod2[["pval.random.w"]][[8]]`


### Assess publication bias
Steps (based on Amit's paper):

1. Visually inspect funnel plots (effect size vs standard error) for bias
2. **If 10 or more studies**, use Egger's Test to test for small-study effect
    + If statistically significant asymmetry found (1-sided P<0.1), use Duval and Tweedie's Trima nd Fill method to quantify magnitude of bias
3. **If <10 studies**, locate outliers in funnel plot and recalculate effect sizes after their removal

To run Egger's, load Egger's function (found [here](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/eggers.test.R))
```{r eggers, include = FALSE}
#' Perform Egger's test of the intercept
#'
#' This function performs Egger's test of the intercept for funnel plot asymmetry using an object
#' of class \code{meta}.
#'
#' @usage eggers.test(x)
#'
#' @param x An object of class \code{meta}, generated by the \code{metabin}, \code{metagen},
#' \code{metacont}, \code{metacor}, \code{metainc}, or \code{metaprop} function.
#'
#' @details Performs Egger's test (Egger et al., 1997) for funnel plot asymmetry.
#' The \code{\link[meta]{metabias}} function is called internally. Egger's test may lack
#' the statistical power to detect bias when the number of studies is small. Sterne et al.
#' (2011) recommend to perform funnel plot asymmetry tests only when \eqn{k \geq 10}. A warning
#' is therefore printed when the number of studies in the \code{meta} object is \eqn{k < 10}.
#'
#' @references
#'
#' Harrer, M., Cuijpers, P., Furukawa, T.A, & Ebert, D. D. (2019).
#' \emph{Doing Meta-Analysis in R: A Hands-on Guide}. DOI: 10.5281/zenodo.2551803. \href{https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/smallstudyeffects.html}{Chapter 9.1}
#'
#' Egger M, Smith GD, Schneider M & Minder C (1997), Bias in meta-analysis detected by a simple,
#' graphical test. \emph{BMJ}, 315, 629â€“634.
#'
#' Sterne, JAC et al. (2011), Recommendations for Examining and Interpreting Funnel Plot
#' Asymmetry in Meta-Analyses of Randomised Controlled Trials. \emph{BMJ}
#' 343, 1, doi: 10.1136/bmj.d4002 .
#'
#' @author Mathias Harrer & David Daniel Ebert
#'
#' @importFrom meta metabias
#' @importFrom graphics abline axis lines mtext par plot points rect segments text
#' @importFrom stats as.formula hat influence ks.test optimize pbinom pchisq pf pnorm pt punif qchisq qf qnorm qt reformulate reorder setNames uniroot
#'
#' @return Returns a data.frame containing the following columns:
#' \itemize{
#' \item \code{Intercept}: The intercept (bias).
#' \item \code{ConfidenceInterval}: The 95\% confidence interval of the intercept.
#' \item \code{t}: The t-statistic for the intercept test.
#' \item \code{p}: The \eqn{p}-value for Egger's test.
#' }
#'
#' @export eggers.test
#'
#' @seealso \code{\link[meta]{metabias}}
#'
#' @examples
#' # Create meta-analysis results using the 'metagen' function
#' suppressPackageStartupMessages(library(meta))
#' data(ThirdWave)
#' m = metagen(TE, seTE, studlab = paste(Author),
#'     data = ThirdWave, comb.random = FALSE, hakn=TRUE)
#'
#' # Plug result into 'eggers.test' function
#' eggers.test(m)


eggers.test = function(x) {

    # Validate
    x = x

    if (x$k < 10) {

        warning(paste("Your meta-analysis contains k =", x$k, "studies. Egger's test may lack the statistical power to detect bias when the number of studies is small (i.e., k<10)."))

    }

    if (class(x)[1] %in% c("meta", "metabin", "metagen", "metacont", "metacor", "metainc", "metaprop")) {

        # Conduct metabias
        eggers = meta::metabias(x, k.min = 3, method = "linreg")

        # Get Intercept
        intercept = as.numeric(eggers$estimate[1]) %>% round(digits = 3)

        # Get SE
        se = as.numeric(eggers$estimate[2])

        # Calculate 95CI
        LLCI = intercept - 1.96 * se %>% round(digits = 1)
        ULCI = intercept + 1.96 * se %>% round(digits = 1)
        CI = paste(LLCI, "-", ULCI, sep = "")

        # Get t
        t = as.numeric(eggers$statistic) %>% round(digits = 3)

        # Get df
        df = as.numeric(eggers$parameters)

        # Get p
        p = as.numeric(eggers$p.value) %>% round(digits = 5)

        # Make df
        df = data.frame(Intercept = intercept, ConfidenceInterval = CI, t = t, p = p)
        row.names(df) = "Egger's test"

    } else {

        stop("x must be of type 'metabin', 'metagen', 'metacont', 'metainc' or 'metaprop'")

    }

    return(df)

}


```

Note: it does not matter which meta-analysis model the funnel plot or Egger's test are conducted based on, as only the individual study effect sizes matter, not the pooled effect size.
HOWEVER, models must be called separately for Trim and Fill.

#### Whole meta-analysis
```{r funnel meta all}
funnel.meta(meta_all_mod1)
```

```{r eggers whole meta}
eggers.test(x = meta_all_mod1)
```

p<0.1, therefore Duval and Tweedie's trim and fill method was used to quantify the magnitude of bias.

```{r duval full meta, results = 'hide'}
meta_all_mod1_trim <- trimfill.meta(meta_all_mod1)
meta_all_mod2_trim <- trimfill.meta(meta_all_mod2)
```

```{r funnel trim full meta}
funnel.meta(meta_all_mod1_trim)
funnel.meta(meta_all_mod2_trim)
```

Results of trim and fill analysis (with 12 studies imputed)

Model | SMD | LL | UL | t (mod1)/z (mod 2) | p-value
------ | ------ | ------ | ------ | ------ | ------
1 | `r meta_all_mod1_trim[["TE.random"]]` |`r meta_all_mod1_trim[["lower.random"]]` | `r meta_all_mod1_trim[["upper.random"]]` | `r meta_all_mod1_trim[["zval.random"]]` | `r meta_all_mod1_trim[["pval.random"]]`
2 | `r meta_all_mod2_trim[["TE.random"]]` | `r meta_all_mod2_trim[["lower.random"]]` | `r meta_all_mod2_trim[["upper.random"]]` | `r meta_all_mod2_trim[["zval.random"]]` | `r meta_all_mod2_trim[["pval.random"]]`

#### Potency
Does not seem possible to plot (using funnel plots) the individual parts of the sub-analyses separately. So, first I will run the meta-analyses separately for each subgroup (code not shown). This will provide the same results as previously found, it just requires extra data wrangling (filtering by subgroup), and more code. 

```{r potency sub analysis, include = FALSE}
dat_pot_low <-dat_study %>%
  filter(Potency == "Low")

meta_low_mod1 <- metagen(g,
                    st_err,
                    data = dat_pot_low,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")

meta_low_mod2 <- metagen(g,
                    st_err,
                    data = dat_pot_low,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")

dat_pot_high <-dat_study %>%
  filter(Potency == "High")

meta_high_mod1 <- metagen(g,
                    st_err,
                    data = dat_pot_high,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")

meta_high_mod2 <- metagen(g,
                    st_err,
                    data = dat_pot_high,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
```

**Low potency**
```{r funnel low pot}
funnel.meta(meta_low_mod1)
```

Egger's:
```{r eggers low pot}
eggers.test(x = meta_low_mod1)
```

P>0.1 so nothing further required, no indication of substantial publication bias.



**High potency**
```{r funnel high pot}
funnel.meta(meta_high_mod1)
```

Egger's:
```{r eggers high pot}
eggers.test(x = meta_high_mod1)
```

p<0.1, therefore Duval and Tweedie's trim and fill method was used to quantify the magnitude of bias.

```{r duval high pot, results = 'hide'}
meta_high_mod1_trim <- trimfill.meta(meta_high_mod1)
meta_high_mod2_trim <- trimfill.meta(meta_high_mod2)
```

```{r funnel trim high pot}
funnel.meta(meta_high_mod1_trim)
funnel.meta(meta_high_mod2_trim)
```

Results of trim and fill analysis (with **XX** studies imputed)

Model | SMD | LL | UL | t (mod1)/z (mod 2) | p-value
------ | ------ | ------ | ------ | ------ | ------
1 | `r meta_high_mod1_trim[["TE.random"]]` |`r meta_high_mod1_trim[["lower.random"]]` | `r meta_high_mod1_trim[["upper.random"]]` | `r meta_high_mod1_trim[["zval.random"]]` | `r meta_high_mod1_trim[["pval.random"]]`
2 | `r meta_high_mod2_trim[["TE.random"]]` | `r meta_high_mod2_trim[["lower.random"]]` | `r meta_high_mod2_trim[["upper.random"]]` | `r meta_high_mod2_trim[["zval.random"]]` | `r meta_high_mod2_trim[["pval.random"]]`



#### Cognitive domains
Again, run subgroup analyses individually first (code not displayed).

```{r domain subanalysis, include=FALSE}
#attention
dat_dom_att <- dat_study_domain %>%
  filter(cog_domain_lezak == "Attention")
meta_att_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_att,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_att_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_att,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#memory
dat_dom_mem <- dat_study_domain %>%
  filter(cog_domain_lezak == "Memory")
meta_mem_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_mem,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_mem_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_mem,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#executive function
dat_dom_exec <- dat_study_domain %>%
  filter(cog_domain_lezak == "Executive Function")
meta_exec_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_exec,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_exec_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_exec,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#psychomotor functioning
dat_dom_psych <- dat_study_domain %>%
  filter(cog_domain_lezak == "Psychomotor Functioning")
meta_psych_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_psych,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_psych_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_psych,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#Concept formation & reasoning
dat_dom_conc <- dat_study_domain %>%
  filter(cog_domain_lezak == "Concept Formation & Reasoning")
meta_conc_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_conc,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_conc_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_conc,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#Language
dat_dom_lang <- dat_study_domain %>%
  filter(cog_domain_lezak == "Language")
meta_lang_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_lang,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_lang_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_lang,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#Intelligence (General)
dat_dom_gen <- dat_study_domain %>%
  filter(cog_domain_lezak == "General")
meta_gen_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_gen,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_gen_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_gen,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
#Perception
dat_dom_perc <- dat_study_domain %>%
  filter(cog_domain_lezak == "Perception")
meta_perc_mod1 <- metagen(g,
                    st_err,
                    data = dat_dom_perc,
                    studlab = paste(study),
                    comb.fixed = F,
                    comb.random = T,
                    method.tau = "SJ",
                    hakn = T,
                    prediction = T, 
                    sm = "SMD")
meta_perc_mod2 <- metagen(g,
                    st_err,
                    data = dat_dom_perc,
                    studlab = paste(author, year),
                    comb.fixed = F,
                    comb.random = T,
                    hakn = F,
                    prediction = T, 
                    sm = "SMD")
```

**Attention**
```{r funnel att}
funnel.meta(meta_att_mod1)
```

Egger's:
```{r eggers att}
eggers.test(x = meta_att_mod1)
```

P>0.1 so nothing further required, no indication of substantial publication bias



**Memory**
```{r funnel mem}
funnel.meta(meta_mem_mod1)
```

Egger's:
```{r eggers mem}
eggers.test(x = meta_mem_mod1)
```

P>0.1 so nothing further required, no indication of substantial publication bias



**Executive function**
```{r funnel exec}
funnel.meta(meta_exec_mod1)
```

Egger's:
```{r eggers exec}
eggers.test(x = meta_exec_mod1)
```

P>0.1 so nothing further required, no indication of substantial publication bias



**Psychomotor functioning**
```{r funnel psych}
funnel.meta(meta_psych_mod1)
```

Egger's:
```{r eggers psych}
eggers.test(x = meta_psych_mod1)
```

p<0.1, therefore Duval and Tweedie's trim and fill method was used to quantify the magnitude of bias.

```{r duval psych, results = 'hide'}
meta_psych_mod1_trim <- trimfill.meta(meta_psych_mod1)
meta_psych_mod2_trim <- trimfill.meta(meta_psych_mod2)
```

```{r funnel trim psych}
funnel.meta(meta_psych_mod1_trim)
funnel.meta(meta_psych_mod2_trim)
```

Results of trim and fill analysis (with **XX** studies imputed)

Model | SMD | LL | UL | t (mod1)/z (mod 2) | p-value
------ | ------ | ------ | ------ | ------ | ------
1 | `r meta_psych_mod1_trim[["TE.random"]]` |`r meta_psych_mod1_trim[["lower.random"]]` | `r meta_psych_mod1_trim[["upper.random"]]` | `r meta_psych_mod1_trim[["zval.random"]]` | `r meta_psych_mod1_trim[["pval.random"]]`
2 | `r meta_psych_mod2_trim[["TE.random"]]` | `r meta_psych_mod2_trim[["lower.random"]]` | `r meta_psych_mod2_trim[["upper.random"]]` | `r meta_psych_mod2_trim[["zval.random"]]` | `r meta_psych_mod2_trim[["pval.random"]]`

**DECIDE WHETHER TO PRINT THE RESULTS PRE TRIM AND FILL NEXT TO THIS AS WELL**



**Concept formation**
```{r funnel conc}
funnel.meta(meta_conc_mod1)
```

Egger's:
```{r eggers conc}
eggers.test(x = meta_conc_mod1)
```

**FURTHER ACTION REQUIRED**



**Language**
```{r funnel lang}
funnel.meta(meta_lang_mod1)
```

<10 studies so Egger's not done

**FURTHER ACTION - assess visually for outliers**



**General**
```{r funnel gen}
funnel.meta(meta_gen_mod1)
```

Egger's:
```{r eggers gen}
eggers.test(x = meta_gen_mod1)
```

**FURTHER ACTION REQUIRED**



**Perception**
```{r funnel perc}
funnel.meta(meta_perc_mod1)
```

<10 studies so Egger's not done

**FURTHER ACTION - assess visually for outliers**